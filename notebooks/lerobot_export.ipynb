{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lerobot transformers num2words onnx onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQNVTzNZVkA6",
        "outputId": "78cab451-7c81-4c6b-d961-e73772352e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lerobot in /usr/local/lib/python3.12/dist-packages (0.3.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.12/dist-packages (0.5.14)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.19.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.22.1)\n",
            "Requirement already satisfied: datasets<=3.6.0,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (3.6.0)\n",
            "Requirement already satisfied: diffusers>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.35.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.2 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (0.34.4)\n",
            "Requirement already satisfied: cmake>=3.29.0.1 in /usr/local/lib/python3.12/dist-packages (from lerobot) (3.31.6)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.8.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (4.12.0.88)\n",
            "Requirement already satisfied: av>=14.2.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (15.1.0)\n",
            "Requirement already satisfied: jsonlines>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (4.0.0)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.12/dist-packages (from lerobot) (25.0)\n",
            "Requirement already satisfied: pynput>=1.7.7 in /usr/local/lib/python3.12/dist-packages (from lerobot) (1.8.1)\n",
            "Requirement already satisfied: pyserial>=3.5 in /usr/local/lib/python3.12/dist-packages (from lerobot) (3.5)\n",
            "Requirement already satisfied: wandb>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.21.1)\n",
            "Requirement already satisfied: torch<2.8.0,>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from lerobot) (2.7.1)\n",
            "Requirement already satisfied: torchcodec<0.6.0,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.5)\n",
            "Requirement already satisfied: torchvision<0.23.0,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.22.1)\n",
            "Requirement already satisfied: draccus==0.10.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.10.0)\n",
            "Requirement already satisfied: gymnasium<1.0.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.29.1)\n",
            "Requirement already satisfied: rerun-sdk<0.23.0,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (0.22.1)\n",
            "Requirement already satisfied: deepdiff<9.0.0,>=7.0.1 in /usr/local/lib/python3.12/dist-packages (from lerobot) (8.6.0)\n",
            "Requirement already satisfied: flask<4.0.0,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from lerobot) (3.1.2)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.34.0 in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot) (2.37.0)\n",
            "Requirement already satisfied: termcolor<4.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from lerobot) (3.1.0)\n",
            "Requirement already satisfied: mergedeep~=1.3 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot) (1.3.4)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot) (6.0.2)\n",
            "Requirement already satisfied: pyyaml-include~=1.4 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot) (1.4.1)\n",
            "Requirement already satisfied: toml~=0.10 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot) (0.10.2)\n",
            "Requirement already satisfied: typing-inspect~=0.9.0 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from num2words) (0.6.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (2025.3.0)\n",
            "Requirement already satisfied: orderly-set<6,>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from deepdiff<9.0.0,>=7.0.1->lerobot) (5.5.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.27.2->lerobot) (8.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.27.2->lerobot) (11.3.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask<4.0.0,>=3.0.3->lerobot) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask<4.0.0,>=3.0.3->lerobot) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask<4.0.0,>=3.0.3->lerobot) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask<4.0.0,>=3.0.3->lerobot) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask<4.0.0,>=3.0.3->lerobot) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask<4.0.0,>=3.0.3->lerobot) (3.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.0.0,>=0.29.1->lerobot) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.0.0,>=0.29.1->lerobot) (0.0.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.2->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (1.1.8)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (0.3.4)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (0.1.9)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (3.0.51)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot) (5.9.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines>=4.0.0->lerobot) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pynput>=1.7.7->lerobot) (1.17.0)\n",
            "Requirement already satisfied: evdev>=1.3 in /usr/local/lib/python3.12/dist-packages (from pynput>=1.7.7->lerobot) (1.9.2)\n",
            "Requirement already satisfied: python-xlib>=0.17 in /usr/local/lib/python3.12/dist-packages (from pynput>=1.7.7->lerobot) (0.33)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot) (2.35.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.20.0->lerobot) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.20.0->lerobot) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.20.0->lerobot) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.20.0->lerobot) (0.4.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect~=0.9.0->draccus==0.10.0->lerobot) (1.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers>=0.27.2->lerobot) (3.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=3.6.0,>=2.19.0->lerobot) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=3.6.0,>=2.19.0->lerobot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=3.6.0,>=2.19.0->lerobot) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.20.0->lerobot) (5.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export SmolVLA's vision backbone (+ connector) to ONNX\n",
        "- Portable: CPU float32, opset=17, no custom ops\n",
        "- Input: pixel_values [B,3,H,W] from the model's processor size\n",
        "- Output: image_hidden_states after connector [B, S_img, D]"
      ],
      "metadata": {
        "id": "ZlAaA3zMc8Z8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9cp7BONL3fV",
        "outputId": "a59a4a83-a278-4355-cb5d-7e149b05e904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting for image size: H=512, W=512\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SmolVLMForConditionalGeneration(\n",
              "  (model): SmolVLMModel(\n",
              "    (vision_model): SmolVLMVisionTransformer(\n",
              "      (embeddings): SmolVLMVisionEmbeddings(\n",
              "        (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
              "        (position_embedding): Embedding(1024, 768)\n",
              "      )\n",
              "      (encoder): SmolVLMEncoder(\n",
              "        (layers): ModuleList(\n",
              "          (0-11): 12 x SmolVLMEncoderLayer(\n",
              "            (self_attn): SmolVLMVisionAttention(\n",
              "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): SmolVLMVisionMLP(\n",
              "              (activation_fn): PytorchGELUTanh()\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (connector): SmolVLMConnector(\n",
              "      (modality_projection): SmolVLMSimpleMLP(\n",
              "        (proj): Linear(in_features=12288, out_features=576, bias=False)\n",
              "      )\n",
              "    )\n",
              "    (text_model): LlamaModel(\n",
              "      (embed_tokens): Embedding(49280, 576, padding_idx=2)\n",
              "      (layers): ModuleList(\n",
              "        (0-29): 30 x LlamaDecoderLayer(\n",
              "          (self_attn): LlamaAttention(\n",
              "            (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
              "            (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
              "            (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
              "            (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
              "          )\n",
              "          (mlp): LlamaMLP(\n",
              "            (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
              "            (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
              "            (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
              "          (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "      (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=576, out_features=49280, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import onnx\n",
        "from onnx import checker, shape_inference\n",
        "import onnxruntime as ort\n",
        "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
        "\n",
        "MODEL_ID = \"HuggingFaceTB/SmolVLM2-256M-Video-Instruct\"\n",
        "# MODEL_ID = \"HuggingFaceTB/SmolVLM2-500M-Video-Instruct\"\n",
        "ONNX_VISION_OUT = Path(\"smolvla_vision_connector.onnx\")\n",
        "ONNX_TEXT_OUT = Path(\"smolvla_embedding.onnx\")\n",
        "OPSET = 17  # safest widely-supported set; increase later if you need newer ops\n",
        "\n",
        "# %% Load processor (for canonical image size) & model\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "\n",
        "# # Determine (H, W) used by the vision encoder\n",
        "# def _resolve_image_hw(proc):\n",
        "#     imgp = getattr(proc, \"image_processor\", None) or getattr(proc, \"image_preprocessor\", None)\n",
        "#     size = getattr(imgp, \"size\", None) or getattr(imgp, \"crop_size\", None)\n",
        "#     if isinstance(size, dict):\n",
        "#         h = size.get(\"height\") or size.get(\"shortest_edge\")\n",
        "#         w = size.get(\"width\")  or size.get(\"shortest_edge\")\n",
        "#         if h is None or w is None:  # fallback if dict doesn’t have h/w keys\n",
        "#             h = w = next(iter(size.values()))\n",
        "#     elif isinstance(size, int):\n",
        "#         h = w = size\n",
        "#     else:  # sensible default if missing\n",
        "#         h = w = 378\n",
        "#     return int(h), int(w)\n",
        "\n",
        "# H, W = _resolve_image_hw(processor)\n",
        "H, W = 512, 512\n",
        "print(f\"Exporting for image size: H={H}, W={W}\")\n",
        "\n",
        "# Load only once, CPU/float32 for portability\n",
        "vlm = AutoModelForImageTextToText.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float32,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "vlm.eval().to(\"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Wrap vision backbone + connector\n",
        "class VisionBackboneConnector(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    pixel_values [B,3,H,W]  ->  vision_model (...) -> connector -> image_hidden_states [B,S_img,D]\n",
        "    \"\"\"\n",
        "    def __init__(self, vlm_model):\n",
        "        super().__init__()\n",
        "        self.vision_model = vlm_model.model.vision_model\n",
        "        self.connector    = vlm_model.model.connector\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor):\n",
        "        # No patch_attention_mask for portability (default=None in upstream code)\n",
        "        vout = self.vision_model(pixel_values=pixel_values, patch_attention_mask=None)\n",
        "        img_hidden = vout.last_hidden_state              # [B, S_img, D_vit]\n",
        "        img_hidden = self.connector(img_hidden)          # [B, S_img, D_llm]\n",
        "        return img_hidden\n",
        "\n",
        "wrapper = VisionBackboneConnector(vlm).eval()\n",
        "for p in wrapper.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "# %% Dummy input (CPU/float32), using model's expected HxW\n",
        "dummy = torch.zeros(1, 3, H, W, dtype=torch.float32)\n",
        "\n",
        "# %% Export to ONNX\n",
        "dynamic_axes = {\"pixel_values\": {0: \"batch\"}, \"image_hidden_states\": {0: \"batch\", 1: \"seq\"}}\n",
        "torch.onnx.export(\n",
        "    wrapper,\n",
        "    (dummy,),\n",
        "    str(ONNX_VISION_OUT),\n",
        "    input_names=[\"pixel_values\"],\n",
        "    output_names=[\"image_hidden_states\"],\n",
        "    do_constant_folding=True,\n",
        "    opset_version=OPSET,\n",
        "    dynamic_axes=dynamic_axes,\n",
        "    training=torch.onnx.TrainingMode.EVAL,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC_MAPVAtHqw",
        "outputId": "d10fd3d7-9b5f-4ee9-c1d8-ba699216d5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/smolvlm/modeling_smolvlm.py:145: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  for batch_idx, p_attn_mask in enumerate(patch_attention_mask):\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/smolvlm/modeling_smolvlm.py:532: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  height = width = int(seq**0.5)\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/smolvlm/modeling_smolvlm.py:538: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  x = x.reshape(bsz, int(seq / (scale_factor**2)), embed_dim * (scale_factor**2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect dims (just informative)\n",
        "hidden = vlm.config.text_config.hidden_size\n",
        "vocab  = vlm.config.text_config.vocab_size\n",
        "print(f\"Text hidden size: {hidden}, vocab: {vocab}\")\n",
        "\n",
        "# %% Wrap text embedder only\n",
        "class TextEmbedder(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    input_ids [B,S] (int64) -> embed_tokens -> float32 embeddings [B,S,D]\n",
        "    \"\"\"\n",
        "    def __init__(self, vlm_model):\n",
        "        super().__init__()\n",
        "        # Use the same path as in smolvlm_with_expert: text_model.get_input_embeddings()\n",
        "        self.embed = vlm_model.model.text_model.get_input_embeddings()\n",
        "\n",
        "    def forward(self, input_ids: torch.LongTensor):\n",
        "        emb = self.embed(input_ids)         # [B,S,D] float32\n",
        "        # Ensure portable dtype\n",
        "        return emb.to(torch.float32)\n",
        "\n",
        "wrapper = TextEmbedder(vlm).eval()\n",
        "for p in wrapper.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "# %% Dummy IDs (tokenization happens outside ONNX; ONNX only maps ids->vectors)\n",
        "dummy_ids = torch.zeros(1, 16, dtype=torch.long)  # [B=1, S=16]\n",
        "\n",
        "dynamic_axes = {\n",
        "    \"input_ids\": {0: \"batch\", 1: \"seq\"},\n",
        "    \"text_embeddings\": {0: \"batch\", 1: \"seq\"},\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6gRbkmQ8BIT",
        "outputId": "303b614c-51a1-40b4-faf9-a53a95e8e48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text hidden size: 576, vocab: 49280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.onnx.export(\n",
        "    wrapper,\n",
        "    (dummy_ids,),\n",
        "    str(ONNX_TEXT_OUT),\n",
        "    input_names=[\"input_ids\"],\n",
        "    output_names=[\"text_embeddings\"],\n",
        "    do_constant_folding=True,\n",
        "    opset_version=OPSET,\n",
        "    dynamic_axes=dynamic_axes,\n",
        "    training=torch.onnx.TrainingMode.EVAL,\n",
        ")\n",
        "\n",
        "# Validate + shape inference (helps downstream tooling)\n",
        "m = onnx.load(str(ONNX_TEXT_OUT))\n",
        "checker.check_model(m)\n",
        "m = shape_inference.infer_shapes(m)\n",
        "onnx.save(m, str(ONNX_TEXT_OUT))\n",
        "print(\"Saved:\", ONNX_TEXT_OUT.resolve())\n",
        "\n",
        "# %% Sanity check with ORT (CPU)\n",
        "sess = ort.InferenceSession(str(ONNX_TEXT_OUT), providers=[\"CPUExecutionProvider\"])\n",
        "out = sess.run([\"text_embeddings\"], {\"input_ids\": dummy_ids.numpy()})[0]\n",
        "print(\"Output shape:\", out.shape)   # expect [1, 16, D]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-M7dhf49Jqy",
        "outputId": "c3db9d8c-4dfd-42e1-a3b3-663b39679a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/smolvla_embedding.onnx\n",
            "Output shape: (1, 16, 576)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnx import helper, TensorProto, checker, shape_inference\n",
        "def patch_gather_idx_to_int64_simple(path: str):\n",
        "    m = onnx.load(path)\n",
        "    g = m.graph\n",
        "\n",
        "    # Gather a set of all existing names to avoid collisions\n",
        "    existing = {vi.name for vi in list(g.input)+list(g.output)+list(g.value_info)}\n",
        "    for n in g.node: existing.update(n.output)\n",
        "    for init in g.initializer: existing.add(init.name)\n",
        "\n",
        "    def uniq(base: str) -> str:\n",
        "        name, k = base, 0\n",
        "        while name in existing:\n",
        "            k += 1\n",
        "            name = f\"{base}_{k}\"\n",
        "        existing.add(name)\n",
        "        return name\n",
        "\n",
        "    cache = {}          # index_tensor_name -> cast_output_name\n",
        "    new_nodes = []\n",
        "\n",
        "    for n in g.node:\n",
        "        if n.op_type == \"Gather\" and len(n.input) >= 2:\n",
        "            data_in, idx_in = n.input[0], n.input[1]\n",
        "\n",
        "            # reuse a single Cast per shared index tensor\n",
        "            cast_out = cache.get(idx_in)\n",
        "            if cast_out is None:\n",
        "                cast_out = uniq(idx_in + \"_to_i64\")\n",
        "                cast_name = uniq(idx_in + \"_CastToInt64\")\n",
        "                cast = helper.make_node(\"Cast\", [idx_in], [cast_out], name=cast_name, to=TensorProto.INT64)\n",
        "                new_nodes.append(cast)\n",
        "                cache[idx_in] = cast_out\n",
        "\n",
        "            # recreate the Gather, preserving attributes and outputs\n",
        "            new_gather = helper.make_node(\n",
        "                \"Gather\",\n",
        "                inputs=[data_in, cast_out] + list(n.input[2:]),\n",
        "                outputs=list(n.output),\n",
        "                name=n.name if n.name else uniq(data_in + \"_Gather\"),\n",
        "            )\n",
        "            new_gather.attribute.extend(list(n.attribute))\n",
        "            new_nodes.append(new_gather)\n",
        "        else:\n",
        "            # copy other nodes as-is\n",
        "            new_nodes.append(n)\n",
        "\n",
        "    # replace nodes (no slice assignment)\n",
        "    g.ClearField(\"node\")\n",
        "    g.node.extend(new_nodes)\n",
        "\n",
        "    # infer & validate\n",
        "    m = shape_inference.infer_shapes(m)\n",
        "    checker.check_model(m)\n",
        "    onnx.save(m, path)\n",
        "    print(\"Patched & saved:\", path)"
      ],
      "metadata": {
        "id": "wOFEsys2tXON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate & add inferred shapes (helps downstream tools)\n",
        "patch_gather_idx_to_int64_simple(str(ONNX_VISION_OUT))\n",
        "print(\"Saved:\", ONNX_VISION_OUT.resolve())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4qPrUkQdF6Q",
        "outputId": "499387f5-c4d5-4117-e681-e90df76e43a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched & saved: smolvla_vision_connector.onnx\n",
            "Saved: /content/smolvla_vision_connector.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "ONNX_OUT = Path(\"smolvla_vision_connector.onnx\")\n",
        "dummy = torch.zeros(1, 3, 512, 512, dtype=torch.float32)\n",
        "# %% Quick runtime sanity check (CPU)\n",
        "sess = ort.InferenceSession(str(ONNX_OUT), providers=[\"CUDAExecutionProvider\"])\n",
        "out = sess.run([\"image_hidden_states\"], {\"pixel_values\": dummy.numpy()})[0]\n",
        "print(\"Output shape:\", out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHZyiYP8uUJv",
        "outputId": "85d09955-3b9e-4e66-8947-7a4f064eaea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (1, 64, 576)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2Ao_69GjRNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}