{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUlDqlOAjgdK",
        "outputId": "1efc3cbb-eb5c-4970-b80f-208d3968b782"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n",
            "Collecting docopt>=0.6.2 (from num2words)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=eaf8e09edb305e688ba7615153c553e3d430377dc97c9685d7a4429ed92ec79d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, num2words, humanfriendly, onnx, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 docopt-0.6.2 humanfriendly-10.0 num2words-0.5.14 onnx-1.19.0 onnxruntime-1.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/huggingface/lerobot.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrioV7iak3Fm",
        "outputId": "d8d81935-a7dd-4cab-da9c-9628160b1710"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lerobot'...\n",
            "remote: Enumerating objects: 37682, done.\u001b[K\n",
            "remote: Counting objects: 100% (829/829), done.\u001b[K\n",
            "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
            "remote: Total 37682 (delta 715), reused 535 (delta 524), pack-reused 36853 (from 4)\u001b[K\n",
            "Receiving objects: 100% (37682/37682), 169.10 MiB | 19.89 MiB/s, done.\n",
            "Resolving deltas: 100% (24349/24349), done.\n",
            "Filtering content: 100% (45/45), 69.04 MiB | 54.97 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd lerobot && pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFvKmI4flnvY",
        "outputId": "5b9a0a1c-5165-4bf8-caac-c233fe7dca43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/lerobot\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets<=3.6.0,>=2.19.0 (from lerobot==0.3.4)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: diffusers>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (0.35.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.2 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4) (0.34.4)\n",
            "Requirement already satisfied: cmake>=3.29.0.1 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (3.31.6)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (0.8.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (4.12.0.88)\n",
            "Collecting av>=14.2.0 (from lerobot==0.3.4)\n",
            "  Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines>=4.0.0 (from lerobot==0.3.4)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (25.0)\n",
            "Collecting pynput>=1.7.7 (from lerobot==0.3.4)\n",
            "  Downloading pynput-1.8.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pyserial>=3.5 (from lerobot==0.3.4)\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: wandb>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (0.21.3)\n",
            "Collecting torch<2.8.0,>=2.2.1 (from lerobot==0.3.4)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchcodec<0.6.0,>=0.2.1 (from lerobot==0.3.4)\n",
            "  Downloading torchcodec-0.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting torchvision<0.23.0,>=0.21.0 (from lerobot==0.3.4)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting draccus==0.10.0 (from lerobot==0.3.4)\n",
            "  Downloading draccus-0.10.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting gymnasium<1.0.0,>=0.29.1 (from lerobot==0.3.4)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rerun-sdk<0.23.0,>=0.21.0 (from lerobot==0.3.4)\n",
            "  Downloading rerun_sdk-0.22.1-cp38-abi3-manylinux_2_31_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting deepdiff<9.0.0,>=7.0.1 (from lerobot==0.3.4)\n",
            "  Downloading deepdiff-8.6.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.34.0 in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.3.4) (2.37.0)\n",
            "Requirement already satisfied: termcolor<4.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.3.4) (3.1.0)\n",
            "Collecting mergedeep~=1.3 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot==0.3.4) (6.0.2)\n",
            "Collecting pyyaml-include~=1.4 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading pyyaml_include-1.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: toml~=0.10 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot==0.3.4) (0.10.2)\n",
            "Collecting typing-inspect~=0.9.0 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2025.3.0)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff<9.0.0,>=7.0.1->lerobot==0.3.4)\n",
            "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.27.2->lerobot==0.3.4) (8.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.27.2->lerobot==0.3.4) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.27.2->lerobot==0.3.4) (0.6.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.27.2->lerobot==0.3.4) (11.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.0.0,>=0.29.1->lerobot==0.3.4) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.0.0,>=0.29.1->lerobot==0.3.4) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.0.0,>=0.29.1->lerobot==0.3.4) (0.0.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.2->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4) (1.1.9)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4) (0.1.9)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4) (3.0.52)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.3.4) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.3.4) (5.9.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines>=4.0.0->lerobot==0.3.4) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pynput>=1.7.7->lerobot==0.3.4) (1.17.0)\n",
            "Collecting evdev>=1.3 (from pynput>=1.7.7->lerobot==0.3.4)\n",
            "  Downloading evdev-1.9.2.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-xlib>=0.17 (from pynput>=1.7.7->lerobot==0.3.4)\n",
            "  Downloading python_xlib-0.33-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.6.80)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.5.4.2)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.3.4) (1.11.1.6)\n",
            "Collecting triton==3.3.1 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot==0.3.4) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot==0.3.4) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot==0.3.4) (4.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot==0.3.4) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot==0.3.4) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.20.0->lerobot==0.3.4) (2.36.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.20.0->lerobot==0.3.4) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.20.0->lerobot==0.3.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.20.0->lerobot==0.3.4) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.20.0->lerobot==0.3.4) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8.0,>=2.2.1->lerobot==0.3.4) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect~=0.9.0->draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers>=0.27.2->lerobot==0.3.4) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.8.0,>=2.2.1->lerobot==0.3.4) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.19.0->lerobot==0.3.4) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.20.0->lerobot==0.3.4) (5.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]>=0.34.2->lerobot==0.3.4) (0.2.13)\n",
            "Downloading draccus-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.6.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pynput-1.8.1-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rerun_sdk-0.22.1-cp38-abi3-manylinux_2_31_x86_64.whl (51.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchcodec-0.5-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading python_xlib-0.33-py2.py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml_include-1.4.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Building wheels for collected packages: lerobot, evdev\n",
            "  Building wheel for lerobot (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lerobot: filename=lerobot-0.3.4-py3-none-any.whl size=595568 sha256=1e36f8710e424495969fd220b99361afe3d255f3af7ae97ea7cf5856653a0f73\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pm9g4cg6/wheels/09/b4/fe/75732b1d640db96ba1f856f2b7328b232a03b696a39cb59686\n",
            "  Building wheel for evdev (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evdev: filename=evdev-1.9.2-cp312-cp312-linux_x86_64.whl size=113493 sha256=90dc80e994e3a01233225a822dbe547756b686e83913a1e293c91e25b7d4372d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f7/62/6b6f5201f6536a3a9e38c94726e03a3b2bded0aaf7782b12d7\n",
            "Successfully built lerobot evdev\n",
            "Installing collected packages: pyserial, nvidia-cusparselt-cu12, triton, torchcodec, rerun-sdk, pyyaml-include, python-xlib, pfzy, orderly-set, nvidia-nccl-cu12, nvidia-cudnn-cu12, mypy-extensions, mergedeep, jsonlines, gymnasium, evdev, av, typing-inspect, pynput, InquirerPy, deepdiff, torch, draccus, torchvision, datasets, lerobot\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed InquirerPy-0.3.4 av-15.1.0 datasets-3.6.0 deepdiff-8.6.1 draccus-0.10.0 evdev-1.9.2 gymnasium-0.29.1 jsonlines-4.0.0 lerobot-0.3.4 mergedeep-1.3.4 mypy-extensions-1.1.0 nvidia-cudnn-cu12-9.5.1.17 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 orderly-set-5.5.0 pfzy-0.3.4 pynput-1.8.1 pyserial-3.5 python-xlib-0.33 pyyaml-include-1.4.1 rerun-sdk-0.22.1 torch-2.7.1 torchcodec-0.5 torchvision-0.22.1 triton-3.3.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import safetensors\n",
        "\n",
        "_VARIANT_RE = re.compile(r\"\\.so\\d+(?:-[\\w]+)?_buffer_\")\n",
        "\n",
        "def canonicalise(k: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove dataset-variant markers like '.so100-blue_' or '.so100_' from a\n",
        "    normalisation-buffer key.\n",
        "    \"\"\"\n",
        "    return _VARIANT_RE.sub(\".buffer_\", k)\n",
        "\n",
        "def standardise_state_dict(\n",
        "    checkpoint: dict[str, torch.Tensor], ref_keys: set[str], *, verbose: bool = True\n",
        ") -> tuple[dict[str, torch.Tensor], list[str]]:\n",
        "    \"\"\"\n",
        "    • Re-keys `checkpoint ` so that every entry matches the *reference* key set.\n",
        "    • If several variant keys collapse to the same canonical name we keep the\n",
        "      first one and log the collision.\n",
        "    • Returns the new dict + a list of entries that could not be matched.\n",
        "    \"\"\"\n",
        "    out, collisions, unmatched = {}, {}, []\n",
        "\n",
        "    for k, v in checkpoint.items():\n",
        "        canon = canonicalise(k)\n",
        "        if canon in ref_keys:\n",
        "            if canon in out:  # duplicate after collapsing\n",
        "                collisions.setdefault(canon, []).append(k)\n",
        "            else:\n",
        "                out[canon] = v\n",
        "        else:\n",
        "            unmatched.append(k)\n",
        "\n",
        "    if verbose:\n",
        "        for canon, variants in collisions.items():\n",
        "            print(f\"[standardise_state_dict] '{canon}'  ←  {variants}\")\n",
        "        if unmatched:\n",
        "            print(f\"[standardise_state_dict] kept {len(unmatched)} unmatched keys\")\n",
        "\n",
        "    out.update({k: checkpoint[k] for k in unmatched})\n",
        "    return out, unmatched\n",
        "\n",
        "def rename_checkpoint_keys(checkpoint: dict, rename_str: str):\n",
        "    \"\"\"\n",
        "    Renames keys in a checkpoint dictionary based on the given rename string.\n",
        "\n",
        "    Args:\n",
        "        checkpoint (dict): The checkpoint dictionary.\n",
        "        rename_str (str): A string specifying key mappings in the format \"old1//new1,old2//new2\".\n",
        "\n",
        "    Returns:\n",
        "        dict: The modified checkpoint with renamed keys.\n",
        "    \"\"\"\n",
        "\n",
        "    rename_dict = dict(pair.split(\"//\") for pair in rename_str.split(\",\"))\n",
        "\n",
        "    new_checkpoint = {}\n",
        "    for k, v in checkpoint.items():\n",
        "        for old_key, new_key in rename_dict.items():\n",
        "            if old_key in k:\n",
        "                k = k.replace(old_key, new_key)\n",
        "        new_checkpoint[k] = v\n",
        "    return new_checkpoint\n",
        "\n",
        "def load_smolvla(\n",
        "    model: torch.nn.Module,\n",
        "    filename: str | os.PathLike,\n",
        "    *,\n",
        "    device: str = \"cpu\",\n",
        "    checkpoint_keys_mapping: str = \"\",\n",
        ") -> torch.nn.Module:\n",
        "    state_dict = safetensors.torch.load_file(filename, device=device)\n",
        "\n",
        "    # Optional user-supplied renames (e.g. \"model._orig_mod.//model.\")\n",
        "    if checkpoint_keys_mapping and \"//\" in checkpoint_keys_mapping:\n",
        "        state_dict = rename_checkpoint_keys(state_dict, checkpoint_keys_mapping)\n",
        "\n",
        "    state_dict, _ = standardise_state_dict(state_dict, set(model.state_dict().keys()))\n",
        "\n",
        "    # HACK(aliberts): to not overwrite normalization parameters as they should come from the dataset\n",
        "    norm_keys = (\"normalize_inputs\", \"normalize_targets\", \"unnormalize_outputs\")\n",
        "    state_dict = {k: v for k, v in state_dict.items() if not k.startswith(norm_keys)}\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    if not all(key.startswith(norm_keys) for key in missing) or unexpected:\n",
        "        raise RuntimeError(\n",
        "            \"SmolVLA %d missing / %d unexpected keys\",\n",
        "            len(missing),\n",
        "            len(unexpected),\n",
        "        )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Wd3g3766AaWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
        "import pprint\n",
        "pprint.pprint(SmolVLAConfig.__dict__)\n"
      ],
      "metadata": {
        "id": "YVBpNgBZg58c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1d76fe-ae04-4544-edad-e039c8fed6a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mappingproxy({'__abstractmethods__': frozenset(),\n",
            "              '__annotations__': {'adapt_to_pi_aloha': <class 'bool'>,\n",
            "                                  'add_image_special_tokens': <class 'bool'>,\n",
            "                                  'attention_mode': <class 'str'>,\n",
            "                                  'chunk_size': <class 'int'>,\n",
            "                                  'empty_cameras': <class 'int'>,\n",
            "                                  'expert_width_multiplier': <class 'float'>,\n",
            "                                  'freeze_vision_encoder': <class 'bool'>,\n",
            "                                  'load_vlm_weights': <class 'bool'>,\n",
            "                                  'max_action_dim': <class 'int'>,\n",
            "                                  'max_period': <class 'float'>,\n",
            "                                  'max_state_dim': <class 'int'>,\n",
            "                                  'min_period': <class 'float'>,\n",
            "                                  'n_action_steps': <class 'int'>,\n",
            "                                  'n_obs_steps': <class 'int'>,\n",
            "                                  'normalization_mapping': dict[str, lerobot.configs.types.NormalizationMode],\n",
            "                                  'num_expert_layers': <class 'int'>,\n",
            "                                  'num_steps': <class 'int'>,\n",
            "                                  'num_vlm_layers': <class 'int'>,\n",
            "                                  'optimizer_betas': tuple[float, float],\n",
            "                                  'optimizer_eps': <class 'float'>,\n",
            "                                  'optimizer_grad_clip_norm': <class 'float'>,\n",
            "                                  'optimizer_lr': <class 'float'>,\n",
            "                                  'optimizer_weight_decay': <class 'float'>,\n",
            "                                  'pad_language_to': <class 'str'>,\n",
            "                                  'prefix_length': <class 'int'>,\n",
            "                                  'resize_imgs_with_padding': tuple[int, int],\n",
            "                                  'scheduler_decay_lr': <class 'float'>,\n",
            "                                  'scheduler_decay_steps': <class 'int'>,\n",
            "                                  'scheduler_warmup_steps': <class 'int'>,\n",
            "                                  'self_attn_every_n_layers': <class 'int'>,\n",
            "                                  'tokenizer_max_length': <class 'int'>,\n",
            "                                  'train_expert_only': <class 'bool'>,\n",
            "                                  'train_state_proj': <class 'bool'>,\n",
            "                                  'use_cache': <class 'bool'>,\n",
            "                                  'use_delta_joint_actions_aloha': <class 'bool'>,\n",
            "                                  'vlm_model_name': <class 'str'>},\n",
            "              '__dataclass_fields__': {'adapt_to_pi_aloha': Field(name='adapt_to_pi_aloha',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'add_image_special_tokens': Field(name='add_image_special_tokens',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'attention_mode': Field(name='attention_mode',type=<class 'str'>,default='cross_attn',default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'chunk_size': Field(name='chunk_size',type=<class 'int'>,default=50,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'device': Field(name='device',type=str | None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'empty_cameras': Field(name='empty_cameras',type=<class 'int'>,default=0,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'expert_width_multiplier': Field(name='expert_width_multiplier',type=<class 'float'>,default=0.75,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'freeze_vision_encoder': Field(name='freeze_vision_encoder',type=<class 'bool'>,default=True,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'input_features': Field(name='input_features',type=dict[str, lerobot.configs.types.PolicyFeature],default=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,default_factory=<class 'dict'>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'license': Field(name='license',type=str | None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'load_vlm_weights': Field(name='load_vlm_weights',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'max_action_dim': Field(name='max_action_dim',type=<class 'int'>,default=32,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'max_period': Field(name='max_period',type=<class 'float'>,default=4.0,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'max_state_dim': Field(name='max_state_dim',type=<class 'int'>,default=32,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'min_period': Field(name='min_period',type=<class 'float'>,default=0.004,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'n_action_steps': Field(name='n_action_steps',type=<class 'int'>,default=50,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'n_obs_steps': Field(name='n_obs_steps',type=<class 'int'>,default=1,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'normalization_mapping': Field(name='normalization_mapping',type=dict[str, lerobot.configs.types.NormalizationMode],default=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,default_factory=<function SmolVLAConfig.<lambda> at 0x79ab823b5e40>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'num_expert_layers': Field(name='num_expert_layers',type=<class 'int'>,default=-1,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'num_steps': Field(name='num_steps',type=<class 'int'>,default=10,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'num_vlm_layers': Field(name='num_vlm_layers',type=<class 'int'>,default=16,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'optimizer_betas': Field(name='optimizer_betas',type=tuple[float, float],default=(0.9, 0.95),default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'optimizer_eps': Field(name='optimizer_eps',type=<class 'float'>,default=1e-08,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'optimizer_grad_clip_norm': Field(name='optimizer_grad_clip_norm',type=<class 'float'>,default=10,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'optimizer_lr': Field(name='optimizer_lr',type=<class 'float'>,default=0.0001,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'optimizer_weight_decay': Field(name='optimizer_weight_decay',type=<class 'float'>,default=1e-10,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'output_features': Field(name='output_features',type=dict[str, lerobot.configs.types.PolicyFeature],default=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,default_factory=<class 'dict'>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'pad_language_to': Field(name='pad_language_to',type=<class 'str'>,default='longest',default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'prefix_length': Field(name='prefix_length',type=<class 'int'>,default=-1,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'private': Field(name='private',type=bool | None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'push_to_hub': Field(name='push_to_hub',type=<class 'bool'>,default=True,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'repo_id': Field(name='repo_id',type=str | None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'resize_imgs_with_padding': Field(name='resize_imgs_with_padding',type=tuple[int, int],default=(512, 512),default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'scheduler_decay_lr': Field(name='scheduler_decay_lr',type=<class 'float'>,default=2.5e-06,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'scheduler_decay_steps': Field(name='scheduler_decay_steps',type=<class 'int'>,default=30000,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'scheduler_warmup_steps': Field(name='scheduler_warmup_steps',type=<class 'int'>,default=1000,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'self_attn_every_n_layers': Field(name='self_attn_every_n_layers',type=<class 'int'>,default=2,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'tags': Field(name='tags',type=list[str] | None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'tokenizer_max_length': Field(name='tokenizer_max_length',type=<class 'int'>,default=48,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'train_expert_only': Field(name='train_expert_only',type=<class 'bool'>,default=True,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'train_state_proj': Field(name='train_state_proj',type=<class 'bool'>,default=True,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'use_amp': Field(name='use_amp',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'use_cache': Field(name='use_cache',type=<class 'bool'>,default=True,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'use_delta_joint_actions_aloha': Field(name='use_delta_joint_actions_aloha',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
            "                                       'vlm_model_name': Field(name='vlm_model_name',type=<class 'str'>,default='HuggingFaceTB/SmolVLM2-500M-Video-Instruct',default_factory=<dataclasses._MISSING_TYPE object at 0x79ac952408c0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD)},\n",
            "              '__dataclass_params__': _DataclassParams(init=True,repr=True,eq=True,order=False,unsafe_hash=False,frozen=False,match_args=True,kw_only=False,slots=False,weakref_slot=False),\n",
            "              '__doc__': 'SmolVLAConfig(n_obs_steps: int = 1, '\n",
            "                         'normalization_mapping: dict[str, '\n",
            "                         'lerobot.configs.types.NormalizationMode] = '\n",
            "                         '<factory>, input_features: dict[str, '\n",
            "                         'lerobot.configs.types.PolicyFeature] = <factory>, '\n",
            "                         'output_features: dict[str, '\n",
            "                         'lerobot.configs.types.PolicyFeature] = <factory>, '\n",
            "                         'device: str | None = None, use_amp: bool = False, '\n",
            "                         'push_to_hub: bool = True, repo_id: str | None = '\n",
            "                         'None, private: bool | None = None, tags: list[str] | '\n",
            "                         'None = None, license: str | None = None, chunk_size: '\n",
            "                         'int = 50, n_action_steps: int = 50, max_state_dim: '\n",
            "                         'int = 32, max_action_dim: int = 32, '\n",
            "                         'resize_imgs_with_padding: tuple[int, int] = (512, '\n",
            "                         '512), empty_cameras: int = 0, adapt_to_pi_aloha: '\n",
            "                         'bool = False, use_delta_joint_actions_aloha: bool = '\n",
            "                         'False, tokenizer_max_length: int = 48, num_steps: '\n",
            "                         'int = 10, use_cache: bool = True, '\n",
            "                         'freeze_vision_encoder: bool = True, '\n",
            "                         'train_expert_only: bool = True, train_state_proj: '\n",
            "                         'bool = True, optimizer_lr: float = 0.0001, '\n",
            "                         'optimizer_betas: tuple[float, float] = (0.9, 0.95), '\n",
            "                         'optimizer_eps: float = 1e-08, '\n",
            "                         'optimizer_weight_decay: float = 1e-10, '\n",
            "                         'optimizer_grad_clip_norm: float = 10, '\n",
            "                         'scheduler_warmup_steps: int = 1000, '\n",
            "                         'scheduler_decay_steps: int = 30000, '\n",
            "                         'scheduler_decay_lr: float = 2.5e-06, vlm_model_name: '\n",
            "                         \"str = 'HuggingFaceTB/SmolVLM2-500M-Video-Instruct', \"\n",
            "                         'load_vlm_weights: bool = False, '\n",
            "                         'add_image_special_tokens: bool = False, '\n",
            "                         \"attention_mode: str = 'cross_attn', prefix_length: \"\n",
            "                         \"int = -1, pad_language_to: str = 'longest', \"\n",
            "                         'num_expert_layers: int = -1, num_vlm_layers: int = '\n",
            "                         '16, self_attn_every_n_layers: int = 2, '\n",
            "                         'expert_width_multiplier: float = 0.75, min_period: '\n",
            "                         'float = 0.004, max_period: float = 4.0)',\n",
            "              '__eq__': <function SmolVLAConfig.__eq__ at 0x79ab823b6480>,\n",
            "              '__hash__': None,\n",
            "              '__init__': <function SmolVLAConfig.__init__ at 0x79ab823b67a0>,\n",
            "              '__match_args__': ('n_obs_steps',\n",
            "                                 'normalization_mapping',\n",
            "                                 'input_features',\n",
            "                                 'output_features',\n",
            "                                 'device',\n",
            "                                 'use_amp',\n",
            "                                 'push_to_hub',\n",
            "                                 'repo_id',\n",
            "                                 'private',\n",
            "                                 'tags',\n",
            "                                 'license',\n",
            "                                 'chunk_size',\n",
            "                                 'n_action_steps',\n",
            "                                 'max_state_dim',\n",
            "                                 'max_action_dim',\n",
            "                                 'resize_imgs_with_padding',\n",
            "                                 'empty_cameras',\n",
            "                                 'adapt_to_pi_aloha',\n",
            "                                 'use_delta_joint_actions_aloha',\n",
            "                                 'tokenizer_max_length',\n",
            "                                 'num_steps',\n",
            "                                 'use_cache',\n",
            "                                 'freeze_vision_encoder',\n",
            "                                 'train_expert_only',\n",
            "                                 'train_state_proj',\n",
            "                                 'optimizer_lr',\n",
            "                                 'optimizer_betas',\n",
            "                                 'optimizer_eps',\n",
            "                                 'optimizer_weight_decay',\n",
            "                                 'optimizer_grad_clip_norm',\n",
            "                                 'scheduler_warmup_steps',\n",
            "                                 'scheduler_decay_steps',\n",
            "                                 'scheduler_decay_lr',\n",
            "                                 'vlm_model_name',\n",
            "                                 'load_vlm_weights',\n",
            "                                 'add_image_special_tokens',\n",
            "                                 'attention_mode',\n",
            "                                 'prefix_length',\n",
            "                                 'pad_language_to',\n",
            "                                 'num_expert_layers',\n",
            "                                 'num_vlm_layers',\n",
            "                                 'self_attn_every_n_layers',\n",
            "                                 'expert_width_multiplier',\n",
            "                                 'min_period',\n",
            "                                 'max_period'),\n",
            "              '__module__': 'lerobot.policies.smolvla.configuration_smolvla',\n",
            "              '__parameters__': (),\n",
            "              '__post_init__': <function SmolVLAConfig.__post_init__ at 0x79ab823b5ee0>,\n",
            "              '__repr__': <function SmolVLAConfig.__repr__ at 0x79ab823b63e0>,\n",
            "              '__subclasshook__': <classmethod(<function _proto_hook at 0x79ac95b94fe0>)>,\n",
            "              '_abc_impl': <_abc._abc_data object at 0x79ab82552140>,\n",
            "              '_is_protocol': False,\n",
            "              'action_delta_indices': <property object at 0x79ab823d8450>,\n",
            "              'adapt_to_pi_aloha': False,\n",
            "              'add_image_special_tokens': False,\n",
            "              'attention_mode': 'cross_attn',\n",
            "              'chunk_size': 50,\n",
            "              'empty_cameras': 0,\n",
            "              'expert_width_multiplier': 0.75,\n",
            "              'freeze_vision_encoder': True,\n",
            "              'get_optimizer_preset': <function SmolVLAConfig.get_optimizer_preset at 0x79ab823b6020>,\n",
            "              'get_scheduler_preset': <function SmolVLAConfig.get_scheduler_preset at 0x79ab823b60c0>,\n",
            "              'load_vlm_weights': False,\n",
            "              'max_action_dim': 32,\n",
            "              'max_period': 4.0,\n",
            "              'max_state_dim': 32,\n",
            "              'min_period': 0.004,\n",
            "              'n_action_steps': 50,\n",
            "              'n_obs_steps': 1,\n",
            "              'num_expert_layers': -1,\n",
            "              'num_steps': 10,\n",
            "              'num_vlm_layers': 16,\n",
            "              'observation_delta_indices': <property object at 0x79ab823d8770>,\n",
            "              'optimizer_betas': (0.9, 0.95),\n",
            "              'optimizer_eps': 1e-08,\n",
            "              'optimizer_grad_clip_norm': 10,\n",
            "              'optimizer_lr': 0.0001,\n",
            "              'optimizer_weight_decay': 1e-10,\n",
            "              'pad_language_to': 'longest',\n",
            "              'prefix_length': -1,\n",
            "              'resize_imgs_with_padding': (512, 512),\n",
            "              'reward_delta_indices': <property object at 0x79ab823d83b0>,\n",
            "              'scheduler_decay_lr': 2.5e-06,\n",
            "              'scheduler_decay_steps': 30000,\n",
            "              'scheduler_warmup_steps': 1000,\n",
            "              'self_attn_every_n_layers': 2,\n",
            "              'tokenizer_max_length': 48,\n",
            "              'train_expert_only': True,\n",
            "              'train_state_proj': True,\n",
            "              'use_cache': True,\n",
            "              'use_delta_joint_actions_aloha': False,\n",
            "              'validate_features': <function SmolVLAConfig.validate_features at 0x79ab823b5f80>,\n",
            "              'vlm_model_name': 'HuggingFaceTB/SmolVLM2-500M-Video-Instruct'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from lerobot.policies.smolvla.smolvlm_with_expert import SmolVLMWithExpertModel\n",
        "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
        "\n",
        "class SmolVLMForONNXExport(nn.Module):\n",
        "    def __init__(self, model_id, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = SmolVLAConfig\n",
        "        self.config.self_attn_every_n_layers = 1 # just test\n",
        "        # Instantiate the real model\n",
        "        # self.model = SmolVLMWithExpertModel(model_id=self.config.vlm_model_name,\n",
        "                                            # attention_mode=\"cross_attn\")\n",
        "        self.model = SmolVLMWithExpertModel(model_id=self.config.vlm_model_name,\n",
        "                                            freeze_vision_encoder=self.config.freeze_vision_encoder,\n",
        "                                            train_expert_only=self.config.train_expert_only,\n",
        "                                            load_vlm_weights=self.config.load_vlm_weights,\n",
        "                                            attention_mode=self.config.attention_mode,\n",
        "                                            num_expert_layers=self.config.num_expert_layers,\n",
        "                                            num_vlm_layers=self.config.num_vlm_layers,\n",
        "                                            self_attn_every_n_layers=self.config.self_attn_every_n_layers,\n",
        "                                            expert_width_multiplier=self.config.expert_width_multiplier)\n",
        "\n",
        "        # Bake in the configuration for the static graph\n",
        "        self.attention_mode = self.config.vlm_model_name\n",
        "        self.num_vlm_layers = self.model.num_vlm_layers\n",
        "        self.num_expert_layers = self.model.num_expert_layers\n",
        "        self.fill_kv_cache = False\n",
        "        self.use_cache = True\n",
        "\n",
        "    def forward(\n",
        "          self,\n",
        "          vlm_embeds: torch.Tensor,\n",
        "          expert_embeds: torch.Tensor,\n",
        "          attention_mask: torch.Tensor,\n",
        "          position_ids: torch.LongTensor,\n",
        "          # Flattened past_key_values: one tensor for keys, one for values per layer\n",
        "          *past_key_values_flat: torch.Tensor):\n",
        "\n",
        "\n",
        "          inputs_embeds = [vlm_embeds, expert_embeds]\n",
        "\n",
        "          past_key_values = {}\n",
        "          if past_key_values_flat:\n",
        "              # Logic to reconstruct the dictionary from the flat tuple of tensors\n",
        "              # This assumes a consistent ordering: (key_layer0, val_layer0, key_layer1, val_layer1, ...)\n",
        "              for i in range(0, len(past_key_values_flat), 2):\n",
        "                  layer_idx = i // 2\n",
        "                  past_key_values[layer_idx] = {\n",
        "                      \"key_states\": past_key_values_flat[i],\n",
        "                      \"value_states\": past_key_values_flat[i+1],\n",
        "                  }\n",
        "          else:\n",
        "              past_key_values = None\n",
        "\n",
        "\n",
        "          fill_kv_cache = past_key_values is None\n",
        "\n",
        "\n",
        "          final_embeds_list, new_past_key_values = self.model.forward(\n",
        "              attention_mask=attention_mask,\n",
        "              position_ids=position_ids,\n",
        "              past_key_values=past_key_values,\n",
        "              inputs_embeds=inputs_embeds,\n",
        "              use_cache=self.use_cache,\n",
        "              fill_kv_cache=self.fill_kv_cache,\n",
        "          )\n",
        "\n",
        "          # --- 3. Flatten Outputs ---\n",
        "          # The output must be a flat tuple of tensors\n",
        "          vlm_output_embeds = final_embeds_list[0]\n",
        "          expert_output_embeds = final_embeds_list[1]\n",
        "\n",
        "          present_key_values_flat = []\n",
        "          if new_past_key_values:\n",
        "            for i in range(self.num_vlm_layers):\n",
        "                if i in new_past_key_values:\n",
        "                    present_key_values_flat.append(new_past_key_values[i][\"key_states\"])\n",
        "                    present_key_values_flat.append(new_past_key_values[i][\"value_states\"])\n",
        "\n",
        "          return (vlm_output_embeds, expert_output_embeds, *present_key_values_flat)"
      ],
      "metadata": {
        "id": "SoQVIbHEFu8Q"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "onnx_model = SmolVLMForONNXExport(\"HuggingFaceTB/SmolVLM2-500M-Video-Instruct\")"
      ],
      "metadata": {
        "id": "_l7b3AANZwXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pprint.pprint(onnx_model.config.num_key_value_heads)\n",
        "# exit(0)\n",
        "\n",
        "\n",
        "onnx_model.eval()\n",
        "\n",
        "onnx_model.fill_kv_cache = True\n",
        "\n",
        "onnx_model.to(\"cuda:0\")\n",
        "\n",
        "output_names = [\"vlm_output_embeds\", \"expert_output_embeds\"]\n",
        "num_layers = onnx_model.model.num_vlm_layers\n",
        "for i in range(num_layers):\n",
        "    output_names.append(f\"present_key_{i}\")\n",
        "    output_names.append(f\"present_value_{i}\")\n",
        "\n",
        "vlm_hidden_dim = onnx_model.model.config.text_config.hidden_size\n",
        "expert_hidden_dim = onnx_model.model.expert_hidden_size\n",
        "\n",
        "batch_size = 1\n",
        "vlm_seq_len = 256\n",
        "expert_seq_len = 16\n",
        "total_seq_len = vlm_seq_len + expert_seq_len\n",
        "\n",
        "dummy_vlm_embeds = torch.randn(batch_size, vlm_seq_len, 960, device=\"cuda:0\", dtype=torch.bfloat16)\n",
        "# dummy_expert_embeds = torch.randn(batch_size, expert_seq_len, 320, device=\"cuda:0\", dtype=torch.bfloat16) # input_embeds\n",
        "dummy_expert_embeds = torch.randn(batch_size, expert_seq_len, expert_hidden_dim, device=\"cuda:0\", dtype=torch.bfloat16) # input_embeds\n",
        "dummy_attn_mask = torch.ones(batch_size, total_seq_len, total_seq_len, device=\"cuda:0\", dtype=torch.bool)\n",
        "dummy_pos_ids = torch.arange(total_seq_len, device=\"cuda:0\").unsqueeze(0)\n",
        "\n",
        "\n",
        "dummy_inputs = (dummy_vlm_embeds, dummy_expert_embeds, dummy_attn_mask, dummy_pos_ids)\n",
        "\n",
        "# we ant past_key_values from it, the second output\n",
        "torch.onnx.export(\n",
        "    onnx_model,\n",
        "    dummy_inputs,\n",
        "    \"smolvlm_expert_prefill.onnx\",\n",
        "    input_names=[\"vlm_embeds\", \"expert_embeds\", \"attention_mask\", \"position_ids\"],\n",
        "    output_names=output_names,\n",
        "    opset_version=17\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCuA_D3JwuzL",
        "outputId": "7299555f-9ccc-4394-8d70-dc8b92f0b5c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lerobot/policies/smolvla/smolvlm_with_expert.py:237: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if seq_len < position_ids.shape[1]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model.config.attention_mode"
      ],
      "metadata": {
        "id": "8L1h0YlM4-II",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fdcf3eef-f79a-4d20-f9ec-b0d8845679a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cross_attn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q ipdb\n",
        "%env PYTHONBREAKPOINT=IPython.core.debugger.set_trace  # makes breakpoint() use ipdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wKrzPx8x6-J",
        "outputId": "74126023-0b56-49b3-f0cc-d82e70dfe24d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.4/1.6 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25henv: PYTHONBREAKPOINT=IPython.core.debugger.set_trace  # makes breakpoint() use ipdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azlQAPDmyEnw",
        "outputId": "484e156c-f8e4-4f2d-b749-aa1e7354a5f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model.to(\"cuda:0\")\n",
        "onnx_model.fill_kv_cache = False\n",
        "onnx_model.use_cache = False"
      ],
      "metadata": {
        "id": "73IqdXIL21_O"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model.use_cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKYVNOqv26sj",
        "outputId": "4d9989fc-f113-4687-ee42-d67bd338b296"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "onnx_model = SmolVLMForONNXExport(\"HuggingFaceTB/SmolVLM2-500M-Video-Instruct\")\n",
        "onnx_model.eval()"
      ],
      "metadata": {
        "id": "SafSe3BbfIgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "onnx_model.to(\"cuda:0\")\n",
        "onnx_model.fill_kv_cache = False\n",
        "onnx_model.self_attn_every_n_layers = -1\n",
        "onnx_model.use_cache = False\n",
        "current_seq_len = 1\n",
        "# past_seq_len = 256\n",
        "past_seq_len = 11\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "vlm_hidden_dim = onnx_model.model.config.text_config.hidden_size\n",
        "expert_hidden_dim = onnx_model.model.expert_hidden_size\n",
        "num_layers = onnx_model.model.num_vlm_layers\n",
        "num_kv_heads = onnx_model.model.config.text_config.num_key_value_heads\n",
        "head_dim = vlm_hidden_dim // onnx_model.model.config.text_config.num_attention_heads\n",
        "\n",
        "dummy_vlm_embeds = torch.randn(batch_size, current_seq_len, 960, device=\"cuda:0\", dtype=torch.bfloat16)\n",
        "dummy_expert_embeds = torch.randn(batch_size, current_seq_len, expert_hidden_dim, device=\"cuda:0\", dtype=torch.bfloat16)\n",
        "# dummy_expert_embeds = torch.randn(batch_size, current_seq_len, 720, device=\"cuda:0\", dtype=torch.bfloat16)\n",
        "# dummy_attn_mask = torch.ones(batch_size, total_seq_len, total_seq_len, device=\"cuda:0\", dtype=torch.bool)\n",
        "# dummy_attn_mask = torch.ones(1, past_seq_len + current_seq_len, past_seq_len + current_seq_len + 1, device=\"cuda:0\", dtype=torch.bool)\n",
        "# dummy_attn_mask = torch.ones(batch_size, 1, past_seq_len + current_seq_len, past_seq_len + current_seq_len + 1, device=\"cuda:0\", dtype=torch.bool)\n",
        "dummy_attn_mask = torch.ones(batch_size, past_seq_len + current_seq_len, past_seq_len + current_seq_len + 1, device=\"cuda:0\", dtype=torch.bool)\n",
        "# dummy_attn_mask = torch.ones(batch_size, 1, past_seq_len, past_seq_len + current_seq_len + 1, device=\"cuda:0\", dtype=torch.bool)\n",
        "# dummy_attn_mask = torch.ones(batch_size, 1, past_seq_len + current_seq_len, device=\"cuda:0\", dtype=torch.bool)\n",
        "dummy_pos_ids = torch.arange(past_seq_len + current_seq_len, device=\"cuda:0\").unsqueeze(0)\n",
        "\n",
        "print(past_seq_len + current_seq_len)\n",
        "print(total_seq_len)\n",
        "\n",
        "input_names = [\"vlm_embeds\", \"expert_embeds\", \"attention_mask\", \"position_ids\"]\n",
        "\n",
        "past_key_values_flat = []\n",
        "for _ in range(num_layers):\n",
        "    key_shape = (batch_size, num_kv_heads, past_seq_len, head_dim)\n",
        "    val_shape = (batch_size, num_kv_heads, past_seq_len, head_dim)\n",
        "    past_key_values_flat.append(torch.randn(key_shape, device=\"cuda:0\", dtype=torch.bfloat16))\n",
        "    past_key_values_flat.append(torch.randn(val_shape, device=\"cuda:0\", dtype=torch.bfloat16))\n",
        "\n",
        "dummy_inputs = (\n",
        "    dummy_vlm_embeds,\n",
        "    dummy_expert_embeds,\n",
        "    dummy_attn_mask,\n",
        "    dummy_pos_ids,\n",
        "    *past_key_values_flat  # Unpack the list into the tuple\n",
        "    # None\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(num_layers):\n",
        "    input_names.append(f\"past_key_{i}\")\n",
        "    input_names.append(f\"past_value_{i}\")\n",
        "\n",
        "\n",
        "# Outputs include the embeddings and the *updated* KV cache\n",
        "output_names = [\"vlm_output_embeds\", \"expert_output_embeds\"]\n",
        "for i in range(num_layers):\n",
        "    # The output names must be consistent for the next iteration\n",
        "    output_names.append(f\"present_key_{i}\")\n",
        "    output_names.append(f\"present_value_{i}\")\n",
        "\n",
        "dynamic_axes = {\"vlm_embeds\": {}, \"expert_embeds\": {}} # Add other static inputs if needed\n",
        "for i in range(num_layers):\n",
        "    # The '2' axis is the sequence length dimension in the KV cache shape\n",
        "    # (batch_size, num_heads, sequence_length, head_dim)\n",
        "    dynamic_axes[f\"past_key_{i}\"] = {2: \"past_sequence_length\"}\n",
        "    dynamic_axes[f\"past_value_{i}\"] = {2: \"past_sequence_length\"}\n",
        "    dynamic_axes[f\"present_key_{i}\"] = {2: \"total_sequence_length\"}\n",
        "    dynamic_axes[f\"present_value_{i}\"] = {2: \"total_sequence_length\"}\n",
        "\n",
        "# we need output_embeds - first output\n",
        "torch.onnx.export(\n",
        "    onnx_model,\n",
        "    dummy_inputs,\n",
        "    \"smolvlm_expert_decode.onnx\",\n",
        "    input_names=input_names,\n",
        "    output_names=output_names,\n",
        "    dynamic_axes=dynamic_axes,\n",
        "    opset_version=17,\n",
        "    do_constant_folding=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "_I5eZPVepZbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320b73c7-ab0f-42b0-80c4-71e476f06765"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, onnx\n",
        "\n",
        "out_name = None\n",
        "src_name = \"smolvlm_expert_prefill.onnx\"\n",
        "out_dir = \"splited\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "base = out_name or (os.path.splitext(os.path.basename(src_name))[0] + \"_ext.onnx\")\n",
        "out_path = os.path.join(out_dir, base)\n",
        "\n",
        "model = onnx.load(src_name)\n",
        "onnx.save_model(\n",
        "        model,\n",
        "        out_path,\n",
        "        save_as_external_data=True,\n",
        "        all_tensors_to_one_file=True,\n",
        "        location=\"weights.bin\",\n",
        "        size_threshold=0,\n",
        "        convert_attribute=True\n",
        "    )"
      ],
      "metadata": {
        "id": "d9KaKiwD115r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, onnx\n",
        "\n",
        "out_name = None\n",
        "src_name = \"smolvlm_expert_decode.onnx\"\n",
        "out_dir = \"splited_decoder\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "base = out_name or (os.path.splitext(os.path.basename(src_name))[0] + \"_ext.onnx\")\n",
        "out_path = os.path.join(out_dir, base)\n",
        "\n",
        "model = onnx.load(src_name)\n",
        "onnx.save_model(\n",
        "        model,\n",
        "        out_path,\n",
        "        save_as_external_data=True,\n",
        "        all_tensors_to_one_file=True,\n",
        "        location=\"weights.bin\",\n",
        "        size_threshold=0,\n",
        "        convert_attribute=True\n",
        "    )"
      ],
      "metadata": {
        "id": "Y9I6Y1WdFR46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}